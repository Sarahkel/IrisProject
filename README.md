# Iris Course Project - Programming and Scripting
GMIT Course Project on exploration of Fisher's Iris Data Set

### Task
> *Imagine that you are to give a brief presentation to your co-workers on the data set, where you explain to them what investigating a data set entails and how Python can be used to do it.
The project entails researching the data set, and then writing documentation and code in the Python programming language based on that research*

**Use:** Python (www.python.org) - Note: Installed with Anaconda (free and open source distribution, comes with over 250 data science packages - find it on: www.anaconda.com)

**Project Plan:** Can be found in GitHub Issues


# Table of Contents
- 1: About Fisher's Iris Data Set
  - References
- 2: Packages used in this project

## 1: About Fisher's Iris Data Set

The data of the Iris Data Set was collected in 1935 by botanist Edgar Anderson. He measured the sepal and petal length and width of 3 different Iris species: *Iris setosa*, *Iris versicolor* and *Iris virginica*. The data set received attention when it was used by British statistician and geneticist Sir Ronald Aylmer Fisher as an example in multivariant discriminate analysis a year later. (1,2)

 ![Petal and sepal demonstrated on species versicolor](http://suruchifialoke.com/img/icon_iris.png)
 
 *[Picture 1](http://suruchifialoke.com/img/icon_iris.png) Petal and sepal demonstrated on species Iris versicolor*

Nowadays the Iris Data Set has become a staple for testing in machine learning and statistics. The data set contains multivariate and real data. For each investigated species 50 instances were measured, totalling 150 instances. Each instance includes measurement of 4 attributes (petal width, petal length, sepal width, sepal length) as well as the corresponding species. The data set is freely available online, the data set used for this project was taken from [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/iris) 

Its appeal for analysis is fittingly described by an online user (3): 
> “small but not trivial” 

> “simple but challenging”

### 1. References
(1)
(2)
(3)

## 2. Packages used in this project

Python has become very popular in Data Science. Packages and built-ins make data analysis with Python accessible and efficient, even if you aren’t an expert programmer.

The easiest way to avail of a variety of useful packages for Python is to download a Python distribution. Personally, I have installed Python through the [Anaconda distribution](https://www.anaconda.com/distribution/). Anaconda claims to be the most popular Python Data Science Distribution and installs 1000+ packages and helps manage these. Some of the popular packages included, and used in this project, are:

**IPython** – “a rich interactive interface, letting you quickly process data and test ideas.” (4) http://ipython.org/

**NumPy** – “the fundamental package for numerical computation. It defines the numerical array and matrix types and basic operations on them.” (4)  http://www.numpy.org/

**Matplotlib** – “a mature and popular plotting package, that provides publication-quality 2D plotting as well as rudimentary 3D plotting” (4) https://matplotlib.org/ 

**Seaborn** – “a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics.”(5)  https://seaborn.pydata.org/

**Pandas** – “providing high-performance, easy to use data structures.” (4) http://pandas.pydata.org/ 

**SciPy Library** – “a collection of numerical algorithms and domain-specific toolboxes, including signal processing, optimization, statistics and much more.” (4) https://www.scipy.org/scipylib/index.html

I found SciPy to provide a great starting point and resource, more information can be found on: https://www.scipy.org/index.html.

### 2. References
(4) https://www.scipy.org/about.html
(5) https://seaborn.pydata.org/

